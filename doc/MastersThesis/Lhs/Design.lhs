\ignore{
\begin{code}
{-# LANGUAGE FlexibleInstances #-}
module MastersThesis.Lhs.Design where
import Control.Monad.Trans.Reader ( ReaderT )
\end{code}
}

In the previous chapter, the importance of making a bridge between two different sets of abstractions --- computers and the physical domain --- was established. This chapter will explain the core philosophy behind the implementation of this link, starting with an introduction to GPAC, followed by the type and typeclass systems used in Haskell, as well as understanding how to model the main entities of the problem. At the end, the presented modeling strategy will justify the data types used in the solution, paving the way for the next chapter \textit{Effectful Integrals}.

\section{Shannon's Foundation: GPAC}
\label{sec:gpac}

The General Purpose Computer or GPAC is a model for the Differential Analyzer --- a mechanical machine controlled by a human operator~\cite{Graca2016}. This machine is composed by a set of shafts interconnected in such a manner that a given differential equation is expressed by a shaft and other mechanical units transmit their values across the entire machine~\cite{Shannon, Graca2004}. For instance, shafts that represent independent variables directly interact with shafts that depicts dependent variables. The machine is primarily composed by four types of units: gear boxes, adders, integrators and input tables~\cite{Shannon}. These units provide useful operations to the machine, such as multiplication, addition, integration and saving the computed values. The main goal of this machine is to solve ordinary differential equations via numerical solutions.

In order to add a formal basis to the machine, Shannon built the GPAC model, a mathematical model sustained by proofs and axioms~\cite{Shannon}. The end result was a set of rules for which types of equations can be modeled as well as which units are the minimum necessary for modeling them and how they can be combined. All algebraic functions (e.g. quotients of polynomials and irrational algebraic functions) and algebraic-trascendental functions (e.g. exponentials, logarithms, trigonometric, Bessel, elliptic and probability functions) can be modeled using a GPAC circuit~\cite{Edil2018, Shannon}. Moreover, the four preceding mechanical units were renamed and together created the minimum set of \textit{circuits} for a given GPAC~\cite{Edil2018}. Figure \ref{fig:gpacBasic} portrays these basic units, followed by descriptions of their behaviour, inputs and outputs.

\figuraBib{GPACBasicUnits}{The combination of these four basic units compose any GPAC circuit (taken from~\cite{Edil2018} with permission)}{}{fig:gpacBasic}{width=.95\textwidth}%

\begin{itemize}
  \item Constant Function: This unit generates a real constant output for any time \textit{t}.
  \item Adder: It generates the sum of two given inputs with both varying in time, i.e., it produces $w = u + v$ for all variations of $u$ and $v$.
  \item Multiplier: The product of two given inputs is generated for all moments in time, i.e., $w = uv$ is the output.
  \item Integrator: Given two inputs --- $u(t)$ and $v(t)$ --- and an initial condition $w_0$ at time $t_0$, the unit generates the output $w(t) = w_0 + \int_{t_0}^{t} u(t) \,dv(t)$, where $u$ is the \textit{integrand} and $v$ is the \textit{variable of integration}.
\end{itemize}

Composition rules that restrict how these units can be hooked to one another. Shannon established that a valid GPAC is the one in which two inputs and two outputs are not interconnected and the inputs are only driven by either the independent variable $t$ (usually \textit{time}) or by a single unit output~\cite{Edil2018, Graca2003, Shannon}. Daniel's GPAC extension, FF-GPAC~\cite{Graca2003}, added new constraints related to no-feedback GPAC configurations while still using the same four basic units. These structures, so-called \textit{polynomial circuits}~\cite{Edil2018, Graca2004}, are being displayed in Figure \ref{fig:gpacComposition} and they are made by only using constant function units, adders and multipliers. Also, such circuits are \textit{combinational}, meaning that they compute values in a \textit{point-wise} manner between the given inputs. Thus, FF-GPAC's composition rules are the following:

\figuraBib{GPACComposition}{Polynomial circuits resembles combinational circuits, in which the circuit respond instantly to changes on its inputs (taken from~\cite{Edil2018} with permission)}{}{fig:gpacComposition}{width=.55\textwidth}%
 
\begin{itemize}
  \item An input of a polynomial circuit should be the input $t$ or the output of an integrator. Feedback can only be done from the output of integrators to inputs of polynomial circuits.
  \item Each polynomial circuit admit multiple inputs.
  \item Each integrand input of an integrator should be generated by the output of a polynomial unit.
  \item Each variable of integration of an integrator is the input \textit{t}.
\end{itemize}

During the definition of the DSL, parallels will map the aforementioned basic units and composition rules to the implementation. With this strategy, all the mathematical formalism leveraged for analog computers will drive the implementation in the digital computer. Although we do not formally prove a refinement between the GPAC theory, i.e., our epurespecification, and the final implementation of \texttt{FACT}, is an attempt to build a tool with formalism taken into account; one of the most frequent critiques in the CPS domain, as explained in the previous chapter.

\section{The Shape of Information}
\label{sec:types}

Types in programming languages represent the format of information. Figure \ref{fig:simpleTypes} illustrates types with an imaginary representation of their shape and Figure \ref{fig:functions} shows how types can be used to restrain which data can be plumbered into and from a function. In the latter image, function \textit{lessThan10} has the type signature \texttt{Int -> Bool}, meaning that it accepts \texttt{Int} data as input and produces \texttt{Bool} data as the output. These types are used to make constratins and add a safety layer in compile time, given that using data with different types as input, e.g, \texttt{Char} or \texttt{Double}, is regarded as a \textit{type error}.

\begin{figure}[ht!]
\centering
\begin{minipage}[t]{.45\textwidth}
  \centering
  \includegraphics[width=0.85\linewidth]{MastersThesis/img/SimpleTypes}
  \captionof{figure}{Types are not just labels; they enhance the manipulated data with new information. Their difference in shape can work as the interface for the data.}
  \label{fig:simpleTypes}
\end{minipage}
\hspace{1cm}
\begin{minipage}[t]{.45\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/PictorialFunction}
  \captionof{figure}{Functions' signatures are contracts; they purespecify which shape the input information has as well as which shape the output information will have.}
  \label{fig:functions}
\end{minipage}
\end{figure}

Primitive types, e.g., \texttt{Int}, \texttt{Double} and \texttt{Char}, can be \textit{composed} to create more powerful data types, capable of modeling complicated data structures. In this context, composition means binding or gluing existent types together to create more sophisticated abstractions, such as recursive structures and records of information. Two \textit{algebraic data types} are the type composition mechanism provided by Haskell to bind existent types together.

The sum type, also known as tagged union in type theory, is an algebraic data type that introduces \textit{choice} across multiple options using a single label. For instance, a type named \texttt{Parity} can represent the parity of a natural number. It has two options or representatives: \texttt{Even} \textit{or} \texttt{Odd}, where these are mutually exclusive. When using this type either of them will be of type \texttt{Parity}. A given sum type can have any number of representatives, but only one of them can be used at a given moment. Figure \ref{fig:sumType} depicts examples of sum types with their syntax in the language, in which a given entry of the type can only assume one of the available possibilities. Another use case depicted in the image is the type \texttt{DigitalStates}, which describes the possible states in digital circuits as one of three options: \texttt{High}, \texttt{Low} and \texttt{Z}.

\begin{figure}[ht!]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \begin{purespec}
  data Parity = Even | Odd

  data DigitalStates = High | Low | Z
  \end{purespec}
\end{minipage}
\begin{minipage}{.49\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/SumType}
\end{minipage}
\caption{Sum types can be understood in terms of sets, in which the members of the set are available candidates for the outer shell type. Parity and possible values in digital states are examples.}
\label{fig:sumType}
\end{figure}

The second type composition mechanism available is the product type, which \textit{combines} using a type constructor. While the sum type adds choice in the language, this data type requires multiple types to assemble a new one in a mutually inclusive manner. For example, a digital clock composed by two numbers, hours and minutes, can be portrayed by the type \texttt{ClockTime}, which is a combination of two separate numbers combined by the wrapper \texttt{Time}. In order to have any possible time, it is necessary to provide \textit{both} parts. Effectively, the product type executes a cartesian product with its parts. Figure \ref{fig:productType} illustrates the syntax used in Haskell to create product types as well as another example of combined data, the type \texttt{SpacePosition}. It represents spatial position in three dimensional space, combining spatial coordinates in a single place. 

\begin{figure}[ht!]
\centering
\begin{minipage}{.57\textwidth}
  \centering
  \begin{purespec}
  data ClockTime = Time Int Int

  data SpacePosition = Point Double Double Double

  data SpacePosition = Point { x :: Double,
                               y :: Double,
                               z :: Double }
  \end{purespec}
\end{minipage}
\begin{minipage}{.4\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/ProductType}
\end{minipage}
\caption{Product types are a combination of different sets, where you pick a representative from each one. Digital clocks' time and objects' coordinates in space are common use cases. In Haskell, a product type can be defined using a \textit{record} alongside with the constructor, where the labels for each member inside it are explicit.}
\label{fig:productType}
\end{figure}

Within algebraic data types, it is possible to abstract the \textit{structure} out, meaning that the outer shell of the type can be understood as a common pattern changing only the internal content. For instance, if a given application can take advantage of integer values but want to use the same configuration as the one presented in the \texttt{SpacePosition} data type, it's possible to add this customization. This feature is known as \textit{parametric polymorphism}, a powerful tool available in Haskell's type system. An example is presented in Figure \ref{fig:parametricPoly} using the \texttt{SpacePosition} type structure, where its internal types are being parametrized, thus allowing the use of other types internally, such as \texttt{Float}, \texttt{Int} and \texttt{Double}.

\begin{figure}[ht!]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \begin{purespec}
  data SpacePosition a = Point a a a

  data SpacePosition a = Point { x :: a,
                                 y :: a,
                                 z :: a }
  \end{purespec}
\end{minipage}
\begin{minipage}{.45\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/ParametricPoly}
\end{minipage}
\caption{Depending on the application, different representations of the same structure need to used due to the domain of interest and/or memory constraints.}
\label{fig:parametricPoly}
\end{figure}

In some situations, changing the type of the structure is not the desired property of interest. There are applications where some sort of \textit{behaviour} is a necessity, e.g., the ability of comparing two instances of a custom type. This nature of polymorphism is known as \textit{ad hoc polymorphism}, which is implemented in Haskell via what is similar to java-like interfaces, so-called \textit{typeclasses}~\cite{Wadler1989}. However, establishing a contract with a typeclass differs from an interface in a fundamental apurespect: rather than inheritance being given to the type, it has a lawful implementation, meaning that \textit{mathematical formalism} is assured for it, although the implementer is not obligated to prove its laws on a language level. As an example, the implementation of the typeclass \texttt{Eq} gives to the type all comparable operations ($==$ and $!=$). Figure \ref{fig:adHocPoly} shows the implementation of \texttt{Ord} typeclass for the presented \texttt{ClockTime}, giving it capabilities for sorting instances of such type.

\begin{figure}[ht!]
\centering
\begin{minipage}{.46\textwidth}
  \centering
  \begin{purespec}
  data ClockTime = Time Int Int

  instance Ord ClockTime where
    (Time a b) <= (Time c d)
      = (a <= c) && (b <= d)

  \end{purespec}
\end{minipage}
\begin{minipage}{.4\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/AdHocPoly}
\end{minipage}
\caption{The minimum requirement for the \texttt{Ord} typeclass is the $<=$ operator, meaning that the functions $<$, $<=$, $>$, $>=$, \texttt{max} and \texttt{min} are now unlocked for the type \texttt{ClockTime} after the implementation. Typeclasses can be viewed as a third dimension in a type.}
\label{fig:adHocPoly}
\end{figure}

Algebraic data types, when combined with polymorphism, are a powerful tool in programming, being a useful way to model the domain of interest. However, both sum and product types cannot portray by themselves the intuition of a \textit{procedure}. A data transformation process, as showed in Figure \ref{fig:functions}, can be utilized in a variety of different ways. Imagine, for instance, a system where validation can vary according to the current situation. Any validation algorithm would be using the same data, such as a record called \texttt{SystemData}, and returning a boolean as the result of the validation, but the internals of these functions would be totally different. This is represented in Figure \ref{fig:pipeline}. In Haskell, this motivates the use of functions as \textit{first class citizens}, meaning that they are values and can be treated equally in comparison with data types that carries information, such as being used as arguments to another functions, so-called high order functions.

\figuraBib{Pipeline}{Replacements for the validation function within a pipeline like the above is common}{}{fig:pipeline}{width=.75\textwidth}%

\section{Modeling Reality}
\label{sec:diff}

The continuous time problem explained in the introduction was initially addressed by mathematics, which represents physical quantities by \textit{differential equations}. This set of equations establishes a relationship between functions and their repurespective derivatives; the function express the variable of interest and its derivative describe how it changes over time. It is common in the engineering and in the physics domain to know the rate of change of a given variable, but the function itself is still unknown. These variables describe the state of the system, e.g, velocity, water flow, electrical current, etc. When those variables are allowed to vary continuously --- in arbitrarily small increments --- differential equations arise as the standard tool to describe them.

While some differential equations have more than one independent variable per function, being classified as a \textit{partial differential equation}, some phenomena can be modeled with only one independent variable per function in a given set, being described as a set of \textit{ordinary differential equations}. However, because the majority of such equations does not have an analytical solution, i.e., cannot be described as a combination of other analytical formulas, numerical procedures are used to solve the system. These mechanisms \textit{quantize} the physical time duration into an interval of numbers, each spaced by a \textit{time step} from the other, and the sequence starts from an \textit{initial value}. Afterward, the derivative is used to calculate the slope or the direction in which the tangent of the function is moving in time in order to predict the value of the next step, i.e., determine which point better represents the function in the next time step. The order of the method varies its precision during the prediction of the steps, e.g, the Runge-Kutta method of 4th order is more precise than the Euler method or the Runge-Kutta of 2nd order.

These numerical methods are used to solve problems purespecified by the following mathematical relations:

\begin{equation}
\dot{y}(t) = f(t, y(t)) \quad y(t_0) = y_0
\label{eq:diffEq}
\end{equation}

As showed, both the derivative and the function --- the mathematical formulation of the system --- varies according to \textit{time}. Both acts as functions in which for a given time value, it produces a numerical outcome. Moreover, this equality assumes that the next step following the derivative's direction will not be that different from the actual value of the function $y$ if the time step is small enough. Further, it is assumed that in case of a small enough time step, the difference between time samples is $h$, i.e., the time step. In order to model this mathematical relationship between the functions and its repurespective derivative, these methods use iteration-based approximations. For instance, the following equation represents one step of the first-order Euler method, the simplest numerical method: 

\begin{equation}
y_{n + 1} = y_n + hf(t_n, y_n)
\label{eq:nextStep}
\end{equation}

So, the next step or iteration of the function $y_{n+1}$ can be computed by the sum of the previous step $y_n$ with the predicted value obtained by the derivative $f(t_n,y_n)$ multiplied by the time step $h$. Figure \ref{fig:eulerExample} provides an example of a step-by-step solution of one differential equation using the Euler method. In this case, the unknown function is a modified exponential function, and the time of interest is $t = 5$.

\begin{figure}[H]
$$ \dot{y} = y + t \quad \quad y(0) = 1 $$
$$ \downarrow $$
$$ y_{n + 1} = y_n + hf(t_n, y_n) \quad h = 1 \quad t_{n + 1} = t_n + h \quad f(t,y) = y + t $$
$$ y_{1} = y_0 + 1 * f(0, y_0) \rightarrow y_{1} = 1 + 1 * (1 + 0) \rightarrow y_{1} = 2 $$
$$ y_{2} = y_1 + 1 * f(1, y_1) \rightarrow y_{2} = 2 + 1 * (2 + 1) \rightarrow y_{2} = 5 $$
$$ y_{3} = y_2 + 1 * f(2, y_2) \rightarrow y_{3} = 5 + 1 * (5 + 2) \rightarrow y_{3} = 12 $$
$$ y_{4} = y_3 + 1 * f(3, y_3) \rightarrow y_{4} = 12 + 1 * (12 + 3) \rightarrow y_{4} = 27 $$
$$ y_{5} = y_4 + 1 * f(4, y_4) \rightarrow y_{5} = 27 + 1 * (27 + 4) \rightarrow y_{5} = 58 $$
\caption{The initial value is used as a starting point for the procedure. The algorithm continues until the time of interest is reached in the unknown function. Due to its large time step, the final answer is really far-off from the expected result.}
\label{fig:eulerExample}
\end{figure}

\section{Making Mathematics Cyber}

Our primary goal is to combine the knowledge levered in section \ref{sec:types} --- modeling capabilities of Haskell's algebraic type system --- with the core notion of differential equations presented in section \ref{sec:diff}. The type system will model equation \ref{eq:nextStep}, detailed in the previous section.

Any representation of a physical system that can be modeled by a set of differential equations has an outcome value at any given moment in time. The type \texttt{CT} (stands for \textit{continuous machine}) in Figure \ref{fig:firstDynamics} is a first draft of representing the continuous physical dynamics~\cite{LeeModeling} --- the evolution of a system state in time:

\begin{figure}[ht!]
\centering
\begin{minipage}{.43\textwidth}
  \centering
  \begin{purespec}
  type Time = Double
  type Outcome = Double
  data CT =
       CT (Time -> Outcome)
  \end{purespec}
\end{minipage}
\begin{minipage}{.56\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/SimpleDynamics}
\end{minipage}
\caption{In Haskell, the \texttt{type} keyword works for alias. The first draft of the \texttt{CT} type is a \textit{function}, in which providing a floating point value as time returns another value as outcome.}
\label{fig:firstDynamics}
\end{figure}

This type seems to capture the concept, whilst being compatible with the definition of a tagged system presented by Lee and Sangiovanni~\cite{LeeSangiovanni}. However, because numerical methods assume that the time variable is \textit{discrete}, i.e., it is in the form of \textit{iterations} that they solve differential equations. Thus, some tweaks to this type are needed, such as the number of the current iteration, which method is being used, in which stage the method is and when the final time of the simulation will be reached. With this in mind, new types are introduced. Figure \ref{fig:dynamicsAux} shows the auxiliary types to build a new version of the \texttt{CT} type.

\ignore{
\begin{code}
data Interval = Interval { startTime :: Double,
                           stopTime  :: Double 
                         } deriving (Eq, Ord, Show)

data Method = Euler
            | RungeKutta2
            | RungeKutta4
            deriving (Eq, Ord, Show)

data Stage = SolverStage Int
           | Interpolate
           deriving (Eq, Ord, Show)

data Solver = Solver { dt        :: Double,     
                       method    :: Method, 
                       stage     :: Stage
                     } deriving (Eq, Ord, Show)

data Parameters = Parameters { interval  :: Interval,
                               solver    :: Solver,
                               time      :: Double,
                               iteration :: Int
                             } deriving (Eq, Show)

\end{code}
}

\begin{figure}[ht!]
\centering
\begin{minipage}{.62\textwidth}
  \centering
\begin{purespec}
data Interval = Interval { startTime :: Double,
                           stopTime  :: Double 
                         } deriving (Eq, Ord, Show)

data Method = Euler
            | RungeKutta2
            | RungeKutta4
            deriving (Eq, Ord, Show)

data Solver = Solver { dt        :: Double,     
                       method    :: Method, 
                       stage     :: Int
                     } deriving (Eq, Ord, Show)

data Parameters = Parameters { interval  :: Interval,
                               solver    :: Solver,
                               time      :: Double,
                               iteration :: Int
                             } deriving (Eq, Show)

\end{purespec}
\end{minipage}
\begin{minipage}{.37\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/DynamicsAuxTypes}
\end{minipage}
\caption{The \texttt{Parameters} type represents a given moment in time, carrying over all the necessary information to execute a solver step until the time limit is reached. Some useful typeclasses are being derived to these types, given that Haskell is capable of inferring the implementation of typeclasses in simple cases.}
\label{fig:dynamicsAux}
\end{figure}

The above auxiliary types serve a common purpose: to provide at any given moment in time, all the information to execute a solver method until the end of the simulation. The type \texttt{Interval} determines when the simulation should start and when it should end. The \texttt{Method} sum type is used inside the \texttt{Solver} type to set solver sensible information, such as the size of the time step, which method will be used and in which stage the method is in at the current moment (more about the stage field on a later chapter). Finally, the \texttt{Parameters} type combines everything together, alongside with the current time value as well as its discrete counterpart, iteration.

Further, the new \texttt{CT} type can also be parametrically polymorphic, removing the limitation of only using \texttt{Double} values as the outcome. Figure \ref{fig:dynamics} depicts the final type for the physical dynamics. The \texttt{IO} wrapper is needed to cope with memory management and side effects, all of which will be explained in the next chapter. Below,
we have the definition for the \texttt{CT} type used in previous work~\cite{Lemos2022}:

\begin{figure}[H]
\centering
\begin{minipage}{.44\textwidth}
  \centering
\begin{purespec}
data CT a = CT (Parameters -> IO a)
\end{purespec}
\end{minipage}
\begin{minipage}{.55\textwidth}
  \centering
  \includegraphics[width=0.95\linewidth]{MastersThesis/img/Dynamics}
\end{minipage}
\caption{The \texttt{CT} type is a function of from time related information to an arbitrary potentially effectful outcome value.}
\label{fig:dynamics}
\end{figure}

In Haskell, however, function types --- types that are carrying a function inside --- are well-known and identified as an instance of a \textit{reader pattern}. The argument
in the function type, in our case \texttt{Parameters}, is called a shared \textit{environment} for the computation of the \texttt{Reader}~\footnote{\texttt{Reader} \href{Reader}{\textcolor{blue}{Hackage reference}}.}. Moreover, because the output of our function type is wrapped inside \texttt{IO}, we can leverage another common abstraction in Haskell:
\textit{monad transformers}. More about Monads will be explained in later chapters, but for now, it suffices to show that our type \texttt{CT} is just a type alias
for a combination of the \textit{reader transformer} -- a combination of the monads \texttt{Reader} with an underlying \texttt{IO} monad within:

\begin{figure}[H]
\centering
\begin{code}
type CT a = ReaderT Parameters IO a
\end{code}
\caption{The \texttt{CT} type can leverage monad transformers in Haskell via \texttt{Reader} in combination with \texttt{IO}.}
\label{fig:dynamics}
\end{figure}

\ignore{
\begin{code}
getSolverStage :: Stage -> Int
getSolverStage (SolverStage st) = st
getSolverStage Interpolate = 0

stageBnds :: Solver -> (Stage, Stage)
stageBnds sl = 
  case method sl of
    Euler -> solverStage (0, 0)
    RungeKutta2 -> solverStage (0, 1)
    RungeKutta4 -> solverStage (0, 3)
  where solverStage (init, end) = (SolverStage init, SolverStage end)

stageLoBnd :: Solver -> Stage
stageLoBnd sc = fst $ stageBnds sc
                  
stageHiBnd :: Solver -> Stage
stageHiBnd sc = snd $ stageBnds sc

instance (Num a) => Num (CT a) where
  x + y = (+) <$> x <*> y
  x - y = (-) <$> x <*> y
  x * y = (*) <$> x <*> y
  negate = fmap negate
  abs = fmap abs
  signum = fmap signum
  fromInteger i = return $ fromInteger i

instance (Fractional a) => Fractional (CT a) where
  x / y = (/) <$> x <*> y
  recip = fmap recip
  fromRational t = return $ fromRational t

instance (Floating a) => Floating (CT a) where
  pi = return pi
  exp = fmap exp
  log = fmap log
  sqrt = fmap sqrt
  x ** y = (**) <$> x <*> y
  sin = fmap sin
  cos = fmap cos
  tan = fmap tan
  asin = fmap asin
  acos = fmap acos
  atan = fmap atan
  sinh = fmap sinh
  cosh = fmap cosh
  tanh = fmap tanh
  asinh = fmap asinh
  acosh = fmap acosh
  atanh = fmap atanh
\end{code}
}

This summarizes the main pilars in the design: FF-GPAC, the mathematical definition of the problem and how we are modeling this domain in Haskell. The next chapter, \textit{Effectful Integrals}, will start from this foundation, by adding typeclasses to the \texttt{CT} type, and will later describe the last core type before explaining the solver execution: the \texttt{Integrator} type. These improvements for the \texttt{CT} type and the new \texttt{Integrator} type will later be mapped to their FF-GPAC counterparts, explaining that they resemble the basic units mentioned in section \ref{sec:gpac}.
