\babel@toc {american}{}\relax 
\babel@toc {american}{}\relax 
\babel@toc {american}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces The translation between the world of software and the mathematical description of differential equations are explicit in the final version of \texttt {FACT}.}}{6}{figure.caption.8}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The combination of these four basic units compose any GPAC circuit (taken from~\cite {Edil2018} with permission).}}{8}{figure.caption.9}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Polynomial circuits resembles combinational circuits, in which the circuit respond instantly to changes on its inputs (taken from~\cite {Edil2018} with permission).}}{9}{figure.caption.10}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Types are not just labels; they enhance the manipulated data with new information. Their difference in shape can work as the interface for the data.}}{10}{figure.caption.11}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Functions' signatures are contracts; they purespecify which shape the input information has as well as which shape the output information will have.}}{10}{figure.caption.11}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Sum types can be understood in terms of sets, in which the members of the set are available candidates for the outer shell type. Parity and possible values in digital states are examples.}}{11}{figure.caption.12}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Product types are a combination of different sets, where you pick a representative from each one. Digital clocks' time and objects' coordinates in space are common use cases. In Haskell, a product type can be defined using a \textbf {record} alongside with the constructor, where the labels for each member inside it are explicit.}}{11}{figure.caption.13}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Depending on the application, different representations of the same structure need to used due to the domain of interest and/or memory constraints.}}{12}{figure.caption.14}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces The minimum requirement for the \texttt {Ord} typeclass is the $<=$ operator, meaning that the functions $<$, $<=$, $>$, $>=$, \texttt {max} and \texttt {min} are now unlocked for the type \texttt {ClockTime} after the implementation. Typeclasses can be viewed as a third dimension in a type.}}{12}{figure.caption.15}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Replacements for the validation function within a pipeline like the above is common.}}{13}{figure.caption.16}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces The initial value is used as a starting point for the procedure. The algorithm continues until the time of interest is reached in the unknown function. Due to its large time step, the final answer is really far-off from the expected result.}}{15}{figure.caption.17}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces In Haskell, the \texttt {type} keyword works for alias. The first draft of the \texttt {CT} type is a \textbf {function}, in which providing a floating point value as time returns another value as outcome.}}{15}{figure.caption.18}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces The \texttt {Parameters} type represents a given moment in time, carrying over all the necessary information to execute a solver step until the time limit is reached. Some useful typeclasses are being derived to these types, given that Haskell is capable of inferring the implementation of typeclasses in simple cases.}}{16}{figure.caption.19}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces The \texttt {CT} type is a function of from time related information to an arbitrary potentially effectful outcome value.}}{17}{figure.caption.20}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces The \texttt {CT} type can leverage monad transformers in Haskell via \texttt {Reader} in combination with \texttt {IO}.}}{17}{figure.caption.21}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Given a parametric record \texttt {ps} and a dynamic value \texttt {da}, the \textit {fmap} functor of the \texttt {CT} type applies the former to the latter. Because the final result is wrapped inside the \texttt {IO} shell, a second \textit {fmap} is necessary.}}{19}{figure.caption.22}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces With the \texttt {Applicative} typeclass, it is possible to cope with functions inside the \texttt {CT} type. Again, the \textit {fmap} from \texttt {IO} is being used in the implementation.}}{20}{figure.caption.23}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces The $>>=$ operator used in the implementation is the \textit {bind} from the \texttt {IO} shell. This indicates that when dealing with monads within monads, it is frequent to use the implementation of the internal members.}}{21}{figure.caption.24}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces The typeclass \texttt {MonadIO} transforms a given value wrapped in \texttt {IO} into a different monad. In this case, the parameter \texttt {m} of the function is the output of the \texttt {CT} type.}}{21}{figure.caption.25}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces The ability of lifting numerical values to the \texttt {CT} type resembles three FF-GPAC analog circuits: \texttt {Constant}, \texttt {Adder} and \texttt {Multiplier}.}}{22}{figure.caption.26}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces State Machines are a common abstraction in computer science due to its easy mapping between function calls and states. Memory regions and peripherals are embedded with the idea of a state, not only pure functions. Further, side effects can even act as the trigger to move from one state to another, meaning that executing a simple function can do more than return a value. Its internal guts can significantly modify the state machine.}}{23}{figure.caption.27}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces The integrator functions attend the rules of composition of FF-GPAC, whilst the \texttt {CT} and \texttt {Integrator} types match the four basic units.}}{28}{figure.caption.28}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The integrator functions are essential to create and interconnect combinational and feedback-dependent circuits.}}{32}{figure.caption.29}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces The developed DSL translates a system described by differential equations to an executable model that resembles FF-GPAC's description.}}{32}{figure.caption.30}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Because the list implements the \texttt {Traversable} typeclass, it allows this type to use the \textit {traverse} and \textit {sequence} functions, in which both are related to changing the internal behaviour of the nested structures.}}{33}{figure.caption.31}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces A \textbf {state vector} comprises multiple state variables and requires the use of the \textit {sequence} function to sync time across all variables.}}{33}{figure.caption.32}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces When building a model for simulation, the above pipeline is always used, from both points of view. The operations with meaning, i.e., the ones in the \texttt {Semantics} pipeline, are mapped to executable operations in the \texttt {Operational} pipeline, and vice-versa.}}{34}{figure.caption.33}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Using only FF-GPAC's basic units and their composition rules, it's possible to model the Lorenz Attractor example.}}{37}{figure.caption.34}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces After \textit {createInteg}, this record is the final image of the integrator. The function \textit {initialize} gives us protecting against wrong records of the type \texttt {Parameters}, assuring it begins from the first iteration, i.e., $t_0$.}}{38}{figure.caption.35}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces After \textit {readInteg}, the final floating point values is obtained by reading from memory a dynamic computation and passing to it the received parameters record. The result of this application, $v$, is the returned value.}}{39}{figure.caption.36}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces The \textit {updateInteg} function only does side effects, meaning that only affects memory. The internal variable \texttt {c} is a pointer to the computation \textit {itself}, i.e., the dynamic computation being created references this exact procedure.}}{39}{figure.caption.37}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces After setting up the environment, this is the final depiction of an independent variable. The reader $x$ reads the values computed by the procedure stored in memory, a second-order Runge-Kutta method in this case.}}{40}{figure.caption.38}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces The Lorenz's Attractor example has a very famous butterfly shape from certain angles and constant values in the graph generated by the solution of the differential equations.}}{41}{figure.caption.39}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces During simulation, functions change the time domain to the one that better fits certain entities, such as the \texttt {Solver} and the driver. The image is heavily inspired by a figure in~\cite {Edil2017}.}}{42}{figure.caption.40}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Updated auxiliary types for the \texttt {Parameters} type.}}{44}{figure.caption.41}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Linear interpolation is a transformation that transition us back to the continuous domain.}}{47}{figure.caption.42}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces The new \textit {updateInteg} function add linear interpolation to the pipeline when receiving a parametric record.}}{48}{figure.caption.43}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces With just a few iterations, the exponential behaviour of the implementation is already noticeable.}}{50}{figure.caption.45}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces The new \textit {createInteg} function relies on interpolation composed with memoization. Also, this combination \textbf {produces} results from the computation located in a different memory region, the one pointed by the \texttt {computation} pointer in the integrator.}}{56}{figure.caption.47}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces The function \textbf {reads} information from the caching pointer, rather than the pointer where the solvers compute the results.}}{57}{figure.caption.48}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces The new \textit {updateInteg} function gives to the solver functions access to the region with the cached data.}}{58}{figure.caption.49}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces Caching changes the direction of walking through the iteration axis. It also removes an entire pass through the previous iterations.}}{59}{figure.caption.50}%
\contentsline {figure}{\numberline {6.6}{\ignorespaces By using a logarithmic scale, we can see that the final implementation is performant with more than 100 million iterations in the simulation.}}{63}{figure.caption.53}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\babel@toc {american}{}\relax 
\babel@toc {american}{}\relax 
\babel@toc {american}{}\relax 
\babel@toc {american}{}\relax 
