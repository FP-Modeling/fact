Chapters 2 and 3 explained the relationship between software, FF-GPAC and the mathematical world of differential equations. As a follow-up, chapter 4 raised intuition and practical understanding of \texttt{Rivika} via a detailed walkthrough of an example. Chapters 5 and 6 identified some problems with the current implementation, such as lack of performance and the discrete time issue, and addressed both problems via caching and interpolation. This chapter, \textit{Conclusion}, draws limitations, future improvements that can bring \texttt{Rivika} to a higher level of abstraction and some final conclusions about the project.

\section{Limitations}

One of the main concerns is the \textbf{correctness} of \texttt{Rivika} between its specification and its final implementation, i.e., refinement. Shannon's GPAC concept acted as the specification of the project, whilst the proposed software attempted to implement it. The criteria used to verify that the software fulfilled its goal were by using it for simulation and via code inspection, both of which are based on human analysis. This connection, however, was \textbf{not} formally verified. Thus, \texttt{Rivika} can be a threat to validity if a future formal verification comes up and checks that the parallel between those two can't be guaranteed.

Further, there is also an issue to regards to \textbf{validation}. In order to know that the mathematical description of the problem is being correctly mapped onto a model representation some formal work needs to be done. This was not explored, and it was considered out of the scope of the project. However, such aspect dictates if the specification for further implementation is actually correct and describes its mathematical counterpart. So, checking for validation is just as important as verifying refinement.

This lack of formalism extends to the typeclasses as well. The programming language of choice, Haskell, does \textbf{not} provide any proofs that the created types actually follow the typeclasses' properties, even if the requested functions type check. This burden is on the developer to manually write down such proofs, a non-explored aspect of this work.

As explained in chapters 1 and 2, there are some extensions that increase the capabilities of Shannon's original GPAC model. One of these extensions, FF-GPAC, was the one chosen to be modeled via software. However, there are other extensions that not only expand the types of functions that can be modeled, e.g., hypertranscendental functions, but also explore new properties, such as Turing universitality~\cite{Graca2004, Graca2016}. The proposed software didn't touch on those enhancements and restricted the set of functions to only algebraic functions.

Finally, there is the language itself, Haskell. Although Haskell's type system allowed a great mapping between the numerical methods and its nuances to created types, its simplicity started to fall apart when impurity came into picture. The side effect overhead makes \texttt{Rivika} hard to reason about, especially for newcomers that intent to expand the software's functionalities.

\section{Future Improvements}

There are solutions to mitigate the problems presented in the previous section. First, to address refinement, the simulation could be assessed by continuous domain specialists. Also, proof-assistant tools, such as COQ and PVS, could be used to re-write \texttt{Rivika} with a proper formal basis, hence establishing a solid map between the mathematical description, specification and implementation. Further, the same tools can leverage the correctness of the typeclasses' implementation, via demonstrating that it assures the axioms and properties demanded by each typeclass. More recent extensions of GPAC should also be explored to simulate an even broader set of functions present in the continuous time domain.

In regards to numerical methods, one of the immediate improvements would be to use \textbf{adaptive} size for the solver time step that \textbf{change dynamically} in run time. This strategy controls the errors accumulated when using the derivative by adapting the size of the time step. Hence, it starts backtracking previous steps with smaller time steps until some error threshold is satisfied, thus providing finer and granular control to the numerical methods, coping with approximation errors due to larger time steps.

In terms of the used technology, some ideas come to mind related to abstracting out duplicated \textbf{patterns} across the code base. The proposed software used a mix of high level abstractions, such as algebraic types and typeclasses, with some low level abstractions, e.g., explicit memory manipulation. An immediate improvement related to this topic would be to abstract the \textbf{stage} information inside the solver using a sum type, \texttt{Stage}, thus removing the use of negative and positive numbers as the trigger for interpolation. On the same line of leveraging abstractions, another major improvement would be to make it entirely \textbf{pure}, meaning that all the necessary side effects would be handled \textbf{only} by high-level concepts internally, hence decreasing complexity of the software. For instance, the memory allocated via \texttt{IORef}~\footnote{\texttt{IORef} \href{https://hackage.haskell.org/package/base-4.16.1.0/docs/Data-IORef.html}{\textcolor{blue}{hackage documentation}}.} acts as a \textbf{state} of the numerical solver; this could be refactored to use the \texttt{ST} monad~\footnote{\texttt{ST} Monad \href{https://wiki.haskell.org/State\_Monad}{\textcolor{blue}{wiki page}}.} This monad deals with state management by itself, removing this weight from the developer.

Further, with the removal of \texttt{IORef} type from the project, the next step would be to change the \texttt{Dynamics} type to not include in its definition the \texttt{IO} monad. As we saw in chapters 2 and 3, this type is heavily coupled to functions that deal with \texttt{IORef} type, such as providing a pointer to a memory region. Moreover, because \texttt{IO} was involved, the typeclass \texttt{MonadIO} became a requirement, given that we need to transition from it to the \texttt{Dynamics} monad in a few situations, like in the \textit{newInteg} function. As a middle step before achieving an implementation based on the \texttt{ST} monad, \textbf{monad transformers}~\footnote{Monad Transformers \href{https://en.wikibooks.org/wiki/Haskell/Monad\_transformers}{\textcolor{blue}{wiki page}}.} provides a more elegant alternative to go back and forth between monads, removing the need for the \texttt{MonadIO} typeclass.

The \texttt{Dynamics} type, which is a function with the signature \texttt{Parameters -> IO a}, resembles the \texttt{Reader} monad~\footnote{\texttt{Reader} Monad \href{https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Reader.html}{\textcolor{blue}{hackage documentation}}.}, a monad that captures the notion of functions. Across the implementation, a lot of intermediate dynamic computations are being created and in the majority of these steps the same record of \texttt{Parameters} is being applied in sequence, creating a chain of functions that are passing the same parameter to one another. By using the \texttt{Reader} monad, this pattern could be abstracted out from the program. This idea, when combined with the \texttt{ST} monad initiative, indicates that the \texttt{RWS} monad~\footnote{\texttt{RWS} Monad \href{https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-RWS-Lazy.html}{\textcolor{blue}{hackage documentation}}.}, a monad that combines the monads \texttt{Reader}, \texttt{Writer} and \texttt{ST}, may be the final goal for a completely pure but effective solution.

Also, there's GPAC and its mapping to Haskell features. As explained previously, some basic units of GPAC are being modeled by the \texttt{Num} typeclass, present in Haskell's \texttt{Prelude} module. By using more specific and customized numerical typeclasses~\footnote{Examples of \href{https://guide.aelve.com/haskell/alternative-preludes-zr69k1hc}{\textcolor{blue}{alternative preludes}}.}, it might be possible to better express these basic units and take advantage of better performance and convenience that these alternatives provide.

Finally, there's the \texttt{MonadFix} typeclass~\cite{Levent1, Levent2, Levent3}~\footnote{\texttt{MonadFix} Monad \href{https://hackage.haskell.org/package/base-4.16.1.0/docs/Control-Monad-Fix.html}{\textcolor{blue}{hackage documentation}}.}~\footnote{\texttt{MonadFix} Monad \href{https://wiki.haskell.org/MonadFix}{\textcolor{blue}{wiki page}}.}; an implemented typeclass used in more recent versions of \texttt{Aivika}. This typeclass uses the mathematical definition of the \textit{fixed-point} concept to compute monadic operations, i.e., it makes it possible to compute the \textbf{fix point} of a computation while being wrapped in a monad, thus being useful for creating loopbacks~\footnote{\texttt{MonadFix} Monad \href{https://github.com/FP-Modeling/fixingAnalog}{\textcolor{blue}{example of use case}}.} within the monad. As the final result, this typeclass abstracts out the \texttt{Integrator} type, meaning that the manipulation of the integrator is no longer maintained by the developer. This shrink in the DSL removes the similarities of the implementation with the GPAC model in some degree, given that the integrator is now implicit. The code below is the same Lorenz Attractor example previously used, but written with this improved version. The main differences are: the absence of the integrator explicitly, the existence of another type that encapsulates the \texttt{Dynamics} type, so-called \texttt{Simulation}, and the use of \texttt{mdo-notation}, also known as \textit{recursive do-notation}~\footnote{Recursive \texttt{do-notation} \href{https://ghc.gitlab.haskell.org/ghc/doc/users\_guide/exts/recursive\_do.html}{\textcolor{blue}{GHC documentation}}.}, rather than \texttt{do-notation}:

\begin{spec}
lorenzModel :: Simulation [IO Vector]
lorenzModel = 
  mdo x <- integ (sigma * (y - x)) 1.0
      y <- integ (x * (rho - z) - y) 1.0
      z <- integ (x * y - beta * z) 1.0
      let sigma = 10.0
          rho = 28.0
          beta = 8.0 / 3.0
      runDynamicsInIntegTimes $ sequence [x, y, z]
\end{spec}

\newpage

\section{Final Thoughts}

When Shannon proposed a formal foundation for the Differential Analyzer~\cite{Shannon}, mathematical abstractions were leveraged to model continuous time. However, after the transistor era, a new set of concepts that lack this formal basis was developed, and some of which crippled our capacity of simulating reality. Later, the need for some formalism made a comeback for modeling physical phenomena with abstractions that take \textit{time} into consideration. Models of computation~\cite{LeeModeling, LeeChallenges, LeeComponent, LeeSangiovanni} and the ForSyDe framework~\cite{Sander2017, Seyed2020} are examples of this change in direction. Nevertheless, Shannon's original idea is now being discussed again with some improvements~\cite{Graca2003, Graca2004, Graca2016} and being transposed to high level programming languages in the hybrid system domain~\cite{Edil2018}.

The \texttt{Rivika} EDSL~\footnote{\texttt{Rivika} \href{https://github.com/FP-Modeling/rivika/releases/tag/1.0}{\textcolor{blue}{source code}}.} follows this path of bringing CPS simulation to the highest level of abstraction, via the Haskell programming language, but still taking into account a formal background inspired by the GPAC model. The software uses advanced functional programming techniques to solve differential equations, mapping the abstractions to FF-GPAC's analog units. Although still limited by the discrete nature of numerical methods, the solution is performant and accurate enough for studies in the cyber-physical domain.
